---
title: "Data-Based Report on Learners' Feedback "
subtitle: ""
author: "Christophe Bontemps"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    df_print: kable
    toc: no
    keep_tex: yes
    fig_width: 6.5
    fig_height: 4
    extra_dependencies: float
  word_document:
    toc: no
  html_document:
    df_print: paged
    toc: yes
    keep_md: yes
    code_folding: show
    fig_width: 6.5
    fig_height: 4
---


```{r Knitr_Global_Options, include=FALSE, cache=FALSE, echo=FALSE}
library(knitr)

# No code is shown here
knitr::opts_chunk$set(echo = FALSE)

# Other options used here 
opts_chunk$set(warning = FALSE, message = FALSE,
               fig.pos = "!H", fig.align = "center",
               autodep = TRUE, tidy = FALSE, cache = TRUE)

# In case of "weird" problem, uncomment the line below (cache issue)
opts_chunk$set(cache.rebuild=TRUE) 

# My colors:
SIAP.color <- "#0385a8"
```

`r if(knitr:::pandoc_to() == "latex") {paste("\\large")}` 


```{r libraries}
# Analysis
library(tidyverse)
library(stringr)
library(dplyr)
library(tidyr)
library(forcats)
library(lubridate)

# Nice presentation of results
library(Cairo)
library(papeR)
library(xtable)
library(data.table)
library(kableExtra)
library(modelsummary)

# Graphics 

library(plotly)
library(wesanderson)
library(patchwork)
library(wordcloud)


#Text analysis
library(stringr)        
library(tm)
### using Tidytext
library(tidytext)  
library(textdata)

```

 

```{r AllCourseParameters}
# List of courses

AllCoursesRef <- c("Gender_Self_1",
                   "DTV20_S",
                   "MLOS_S", 
                   "HealthStats2",
                   "SEEA_CF_2022", 
                   "SBR22", 
                   "MLOS22", 
                   "ClimateChange2023", 
                   "user_2023", 
                   "egriss_2023")

AllCoursesNameLong <-c( "Using gender data for analysis, communications and policy making in the context of SDG monitoring and beyond",
                        "Principles of Data Visualization for Official Statistics and SDG Indicators",
                        "Principles of Machine Learning for Official Statistics and SDGs", 
                        "Health Statistics for Monitoring Sustainable Development Goals (SDGs) - 2022",
                        "Introduction to the System of Environmental Economic Accounting-Central Framework", 
                        "Statistical Business Registers", 
                        "Machine Learning for Official Statistics and SDGs-2022", 
                        "Compiling climate change indicators: an accounting approach", 
                        "Increasing User Engagement Around Data and Statistics", 
                        "Introduction to International Recommendations on Refugee and IDP Statistics")

AllCoursesStartDate <-c("2022-05-25", "2022-01-24", "2022-06-06", "2022-07-04", "2022-08-01", "2022-09-26", "2022-11-21", "2023-01-16", "2023-03-27", "2023-03-13 ")
AllCoursesNbModules <-c(3,6,6,5,5,7,8, 6, 6)
```


```{r CourseChoice}
# Course Index <<<<<< =====  Choose the course here
#i.course <- 1  # Gender
# i.course <- 2  # Dataviz -self
# i.course <- 3  # MLOS- Self
# i.course <- 4  # Health
# i.course <- 5 # SEEA Central Framework
# i.course <- 6 # SBR
#i.course <- 7 # MLOS22
# i.course <-8 # Climate Change 2023
# i.course <-9 # User Engagement
i.course <-10 # Refugees <--- NO MOST USED WORDS IN THIS REPORT (Blank for whatever reason)  results = 'hide' in the TopWords


```


```{r CourseParameters}
# Course general parameters
CourseName <- AllCoursesRef[i.course]    
CourseNameLong <- AllCoursesNameLong[i.course]
CourseStartDate <-AllCoursesStartDate[i.course]
NbModules <- AllCoursesNbModules[i.course]              



```
# ***`r CourseNameLong `***:  

## Data sets

```{r LoadData}
# Parse the data folder to find the latest files 

#### Feedback  File
# --> use Comma separated values

list.feedback<- list.files(path="Data/",pattern = glob2rx(paste0("Feedback*",CourseName,"*")),
                       full.names = TRUE,recursive = TRUE)
name_last_feedback <- list.feedback[which.max(file.mtime(list.feedback))]
data.feedback <- read.csv(name_last_feedback, encoding = "utf-8")
#data.feedback <- read.csv(name_last_feedback, locale = locale(encoding = "Latin1"))

# Date of the last file found
FileDate <-as_date(file.mtime(name_last_feedback))

```

```{r RenameVars}
# I split the string (strsplit) at a dot (which you need to escape using \\) and take out only the second element using lapply. unlist is there to coerce the list into a vector.
names(data.feedback)[c(2, 4, 5)] <- c("G.groups", "c.Country", "D.Date")

names(data.feedback) <- unlist(lapply(strsplit(names(data.feedback), "\\."), "[[", 2))

# Saving questions could be a good idea (does not work)
# questions <-  unlist(lapply(strsplit(names(data.feedback), "\\.."), "[[", 2))



```


```{r NonUnicode}
# remove comments written in Chinese (maybe not necessary since we imported in utf-8)
#data.feedback$Results  <- str_replace_all(data.feedback$Results, "[\u2E80-\u2FD5\u3190-\u319f\u3400-\u4DBF\u4E00-\u9FCC\uF900-\uFAAD]", "")

data.feedback$Comments  <- str_replace_all(data.feedback$Comments, "[\u2E80-\u2FD5\u3190-\u319f\u3400-\u4DBF\u4E00-\u9FCC\uF900-\uFAAD]", "")
```


Our analysis uses the data collected on **`r FileDate`** from the  **Feedback Form** on the Moodle platform^[file `r name_last_feedback`]. **`r nrow(data.feedback)`** different learners provided **anonymously** their feedback and comments on the course.^[As of `r format(FileDate, "%A %d %B")`]

## Composition of the respondants

```{r StatDesc, cache =TRUE}
G_Sex <- data.feedback %>%
    ggplot() +
    aes(x= Gender ) +
    geom_histogram(stat = "count", fill = SIAP.color) +
    ggtitle("Gender") +
    coord_flip() +
    theme_minimal()

G_Org <- data.feedback %>%
  ggplot() +
  aes(x= Organization ) +
  geom_histogram(stat = "count", fill = SIAP.color) +
  ggtitle("Organization") +
  coord_flip() +
  theme_minimal()



```


```{r GraphicOrganisation}

# G_Sex + G_Org + 
#   plot_annotation(title = 'Respondents:',
#                   caption = paste("Based on" , nrow(data.feedback)," responses (File date", FileDate,")"),
#                   theme = theme(plot.title = element_text(size = 16))) 

```



```{r TransformFactors}
# Transforming answers into factors
library(purrr)

# Define a function to harmonize the answers
harmonize_answers <- function(answer) {
  answer <- tolower(answer)
  if (grepl("strongly agree", answer)) {
    return("Strongly agree")
  } else if (grepl("somewhat agree", answer)) {
    return("Somewhat agree")
  } else if (grepl("strongly disagree", answer)) {
    return("Strongly disagree")
  } else if (grepl("disagree", answer)) {
    return("Disagree")
  } else if (grepl("agree", answer)) {
    return("Agree")
  } else {
    return(NA)
  }
}


# Define a function to convert a variable into a factor with 6 levels
factor_6_levels <- function(variable) {
  variable <- factor(variable, levels = c("Strongly disagree", "Disagree", "Somewhat disagree", "Somewhat agree", "Agree", "Strongly agree"))
  return(variable)
}

```


```{r GraphicFunction}
library(rlang)
Response_plot <- function(data, xvar, title) {
  # Harmonize the answers for each variable
  data[[xvar]]<- sapply(data[[xvar]], harmonize_answers)

  # Convert each variable into a factor with 6 levels
   data[[xvar]] <- factor_6_levels( data[[xvar]])
  
  # Graphic

  ggplot(data)+
  aes_string(x= xvar) +
  geom_histogram(stat = "count", fill = SIAP.color, alpha = 0.5) +
  ggtitle(paste(title)) +
  coord_flip() +
  theme_minimal( ) +
 theme(legend.position = "none", 
       plot.title = element_text(size = 10))
}
```


```{r SurveyNewFormat, cache=TRUE}
# Creating Graphics
## Relevance: (3 questions)

G_R1 <- Response_plot(data.feedback, "Relevance1", "The training was relevant to my work.")
G_R2 <- Response_plot(data.feedback, "Relevance2", "The level of e-learning course content was \n appropriate for my professional background")
G_R3 <- Response_plot(data.feedback, "Relevance3", "The scope of the e-learning course was appropriate" )

## Effectiveness: (4 questions)

G_E1 <- Response_plot(data.feedback, "Effectiveness1", "The training effectively enhanced my knowledge \n and skills.")
G_E2 <- Response_plot(data.feedback, "Effectiveness2", "My confidence has improved in applying \n the training  received in my work.")
G_E3 <- Response_plot(data.feedback, "Effectiveness3", "The training method was appropriate and effective.")
G_E4 <- Response_plot(data.feedback, "Effectiveness4", "The course content (interactive lessons) was \n of high quality, clear and concise.  ")

##Efficiency: (2 questions)

G_Y1 <- Response_plot(data.feedback, "Efficiency1", "I was satisfied with the technical support provided \n on the SIAP e-learning platform.")
G_Y2 <- Response_plot(data.feedback, "Efficiency2", "I was satisfied with navigating the SIAP \n e-learning platform." )

```


#  Evaluation of the different dimensions of the course

We asked the participants to value their experience on the course using a 5-level scale, on 3 different dimensions: 
- **Relevance**: (3 questions)
- **Effectiveness**: (4 questions)
- **Efficiency**: (2 questions)

## Relevance


```{r GraphicsRelev, fig.height=6}
all.R<- (G_R1 +G_R2) /G_R3 
all.R + 
  plot_annotation(title = 'Relevance of the course',
                  caption = paste("Based on" , nrow(data.feedback)," responses (File date", FileDate,")"),
                  theme = theme(plot.title = element_text(size = 16))) 

```

## Effectiveness


```{r GraphicsEff, fig.height=6}
all.E <- (G_E1 | G_E2) /(G_E3 | G_E4) 
all.E + 
  plot_annotation(title = 'Effectiveness of the course',
                  caption = paste("Based on" , nrow(data.feedback)," responses (File date", FileDate,")"),
                  theme = theme(plot.title = element_text(size = 16))) 

```


## Efficiency


```{r GraphicsEffy, fig.height=6}
all.Y <- (G_Y1 / G_Y2) 
all.Y + 
  plot_annotation(title = 'Efficiency of the course',
                  caption = paste("Based on" , nrow(data.feedback)," responses (File date", FileDate,")"),
                  theme = theme(plot.title = element_text(size = 16))) 

```



<!-- # Consistency of the responses -->

```{r textdata}

data.text <- data.feedback %>%
  select(share, Effectiveness_open, Comments, FinalComments )

data.survey <- data.feedback %>%
  select(Relevance1:Relevance3, Effectiveness1:Effectiveness4, Efficiency1:Efficiency2)

```


```{r}
# 
# # Function to convert character variables to numeric
# char_to_num <- function(x) {
#   x_levels <- c("Strongly disagree", "Disagree", "Somewhat disagree", "Somewhat agree", "Agree", "Strongly agree")
#   as.numeric(factor(x, levels = x_levels)) -1
# }
# 
# # Apply function to all character variables in data frame
# data.num<- lapply(data.survey, function(x) if (is.character(x)) char_to_num(x) else x)
# names(data.num) <- paste(names(data.num), "N", sep = "_")
# 
# data.feedback <- cbind(data.feedback, data.num)

```



```{r numericscale}
# data.num[1:10] <-data.num[, 1:10] %>%
#    mutate_if(is.character,as.factor)
# 
# 
# data.num <- data.num %>%
#   mutate_at(
#     vars(one_of('Knowledge', 'Content', 'Efficiency','Quality', 'Design', 'Usefulness'  )),
#     funs(case_when(
#      . == "Strongly disagree" ~ 0,
#      . =="Somewhat disagree" ~ 1,
#      . == "Disagree" ~ 2,
#      . == "Agree" ~ 3,
#      . == "Somewhat agree" ~ 4,
#      . == "Strongly agree" ~ 5))
#   )
# 
# # Total score
# data.num <- data.num %>%
#   mutate( Total = Knowledge + Content + Efficiency +
#                   Quality + Design + Usefulness)
```



```{r PCP, eval = FALSE}
# library(GGally)
# library(viridis)
# library(hrbrthemes)

# data.num %>%
#   select(Gender,Knowledge:Usefulness) %>%
#   mutate_if(is.numeric, as.factor) %>%
# ggparcoord(
#    columns = c(2:7), 
#    groupColumn = "Gender",
#    scale = "globalminmax",
#    order = "anyClass",
#     title = "No scaling",
#     alphaLines = 0.3
#     ) +
#  theme_minimal() +
#   theme(
#     plot.title = element_text(size=10), 
#     axis.text.x =  element_text(size=9, angle = 60, hjust = 1), 
#     #axis.text.x =  element_blank(),
#     legend.position = "bottom"
#   )
```

```{r}
# https://github.com/heike/ggpcp
# install.packages("devtools")
# remotes::install_github("heike/ggpcp")
```

<!--  We represent each evaluation by a line joining the score for each question. The line for a participant with always the same answer (e.g. "Strongly agree") should be horizontal. The  colors her reflect the gender. -->

```{r}
# library(ggpcp)
# data.num %>%
# mutate_if(is.numeric, as.factor) %>%
# arrange(Knowledge, Content, Total)%>%
# pcp_select(5:10) %>%
#   pcp_scale(method = "uniminmax") %>%
#   pcp_arrange(method="from-right") %>%
#   ggplot(aes_pcp()) + 
#     geom_pcp(aes(colour = Gender ),
#              alpha = 0.6, axiswidth = c(0,0))+
#     scale_colour_manual(values=c("darkorange", "steelblue", "grey")) +
#     guides(colour=guide_legend(override.aes = list(alpha=1)))+
#   # geom_pcp_labels() +
#   labs(title = "Consistency of responses",
#        caption = paste(" Each line is one response, ",
#                        "based on", nrow(data.feedback), "responses"), 
#        y = " Responses",
#        x = "Topics in the form")+
#   
#  theme_minimal() +
#   theme(
#     plot.title = element_text(size=10), 
#     axis.text.x =  element_text(size=9, angle = 60, hjust = 1), 
#     #axis.text.x =  element_blank(),
#     legend.position = "right"
#   ) 
  



```

# Text analysis from the open fields

```{r Questions}
Text.R <- "Please share comments and suggestions on how to improve the relevance of the training to your work. "
Text.E <- "Please share comments and suggestions on how to improve the effectiveness of the course in enhancing your skills and knowledge."
Text.C <- "Please share further comments and suggestions, if any, on logistical arrangements of the e-learning course."
Text.F <-"Please let us know of any other comments you would like to share with us about the course."


```

Free-text comments are probably the most valuable elements for lecturers as suggestions and relevant critics can be spotted in these comments. We have **four** different free-text questions in the feedback form for this course: 

- *`r Text.R`* 
- *`r Text.E`*
- *`r Text.C`* 
- *`r Text.F`*


We provide here a first descriptive analysis of the comments received. This analysis is quite crude, but allows to spot some of the most important terms used by the participants in their comments. 
`

```{r TextCleaning}
# from https://www.r-bloggers.com/2021/05/sentiment-analysis-in-r-3/


# Get text corpus
# remove some specific terms
data.text <- data.text %>%
   mutate_all(~gsub("use |machine |learning| learned|can| training|
                    |course| will |data", "", .))
```

## Word cloud on *Relevance* and *Effectiveness*


```{r TextRelevance}
# Create corpus
All.Comments.R <- rbind(data.text$share, data.text$Effectiveness_open)
corpus.R <- iconv(All.Comments.R)
corpus.R <- Corpus(VectorSource(corpus.R))

# Clean text
corpus.R <- tm_map(corpus.R, tolower)
corpus.R <- tm_map(corpus.R, removePunctuation)
corpus.R <- tm_map(corpus.R, removeNumbers)

cleanset.R <- tm_map(corpus.R, removeWords, stopwords('english'))
# inspect(cleanset.R[1:5])

#Text stemming – which reduces words to their root form
#cleanset.R <- tm_map(cleanset.R, stemDocument)
cleanset.R <- tm_map(cleanset.R, stripWhitespace)

# we reduce the dimension here 
#cleanset.R <- cleanset.R[1:100]

```

```{r TopWordsRelevance, fig.height=6, results ='hide', fig.show='hide'}
### NO FIGURE SHOWED HERE !!!

Terms.R <- TermDocumentMatrix(cleanset.R)
Terms.R <- as.matrix(Terms.R)

Words.R <- rowSums(Terms.R)
Words.R <- subset(Words.R, Words.R>=40)

barplot(Words.R,
        main = "Most popular words (Relevance and Effectiveness)", 
        # sub = "Relevance and Effectiveness",
        xlim = c(0, 100), 
        ylim = c(0, 100), 
        las = 2,
        horiz=TRUE,
        col = SIAP.color)

```

```{r}

Words.R <- sort(rowSums(Terms.R), decreasing = TRUE)
set.seed(222)
wordcloud(words = names(Words.R),
          freq = Words.R,
          max.words = 150,
          random.order = F,
          min.freq = 5,
          colors = brewer.pal(8, 'Dark2'),
          scale = c(3, 0.6),
          rot.per = 0.2)
```

## Word cloud on *Comments* 


```{r TextComments}
# Create corpus
All.Comments.C <- rbind(data.text$Comments, data.text$FinalComments)
corpus.C <- iconv(All.Comments.C)
corpus.C <- Corpus(VectorSource(corpus.C))

# Clean text
corpus.C <- tm_map(corpus.C, tolower)
corpus.C <- tm_map(corpus.C, removePunctuation)
corpus.C <- tm_map(corpus.C, removeNumbers)

cleanset.C <- tm_map(corpus.C, removeWords, stopwords('english'))
# inspect(cleanset.C[1:5])

#Text stemming – which reduces words to their root form
#cleanset.C <- tm_map(cleanset.C, stemDocument)
cleanset.C <- tm_map(cleanset.C, stripWhitespace)
#inspect(cleanset.C[1:5])

```

```{r TopWordsComments, fig.height=6,  results ='hide', fig.show='hide'}
### NO FIGURE SHOWED HERE !!!

Terms.C <- TermDocumentMatrix(cleanset.C)
Terms.C <- as.matrix(Terms.C)

Words.C <- rowSums(Terms.C)
Words.C <- subset(Words.C, Words.C>=25)

barplot(Words.C,
        main = "Most popular words (comments)", 
        #sub = Text.C,
        xlim = c(0, 1000), 
        ylim = c(0, 10), 
        las = 2,
        horiz=TRUE,
        col = SIAP.color)

```

```{r}

Words.C <- sort(rowSums(Terms.C), decreasing = TRUE)
set.seed(222)
wordcloud(words = names(Words.C),
          freq = Words.C,
          max.words = 150,
          random.order = F,
          min.freq = 5,
          colors = brewer.pal(8, 'Dark2'),
          scale = c(3, 0.6),
          rot.per = 0.2)
```







\newpage

#  Sentiment analysis

We  use *sentiment analysis* to determine  whether comments belong to some sort of  " predefined opinions". This method is basically a classification algorithm based on a reference list (*Word-Emotion Association Lexicon*, Mohammad and Turney 2013) where a large set of words are already classified as "positive", "negative", "happy", "sad", "angry", etc. We use here the  comments left by the participants on the free-text fields in the evaluation form  as the raw corpus of text.  

Each comment is decomposed into words^[Only "meaningful"  extracted from each sentence, excluding stop words like  “the", "is", "at", "on”]  associated to its semantic root  ([*Stemmization*](https://towardsdatascience.com/stemming-lemmatization-what-ba782b7c0bd8) ) in order to reduce the complexity of the process. After cleaning each "meaningful"  word can be related (or not) to one class *i.e.* to a sentiment.

Each comment can then be associated with one or several "sentiments" in a matrix form and some statistics can be derived, including a basic count for each category, as below:  


```{r SentimentScores, cache=TRUE}


library(syuzhet) # For generating sentiment scores

cleanset <- c(unlist(cleanset.R),unlist(cleanset.C))
# This takes time
scores <- get_nrc_sentiment(cleanset)



# The tidytext version consist of matching with NRC sentiment source
# see https://ladal.edu.au/sentiment.html
# nrc <-tidytext::get_sentiments("nrc")
```


```{r}
counts <-colSums(scores)
barplot(counts, horiz = TRUE, 
        col = "lightblue", 
        xlim = c(0, max(counts) * 1.1), 
        las = 2,
        border = NA,
        main = "Sentiment Scores (All text) ")

text(x = counts, 
     y = 1:length(counts), 
     labels = paste0(names(counts), ": ", counts), 
     col = "blue", pos = 3)
```


\newpage

# Comments from learners

```{r nbAnswers}
# Nb Answers shown 
NbAnswers <-20

```


Since the number of comments can be important (we have `r  nrow(data.feedback)` responses), we  computed a score of satisfaction based on the 5-level scale used for each closed-form question.^[ For each question, a score from 0 ("*Strongly disagree*") to 5 ("*Strongly agree*") was attributed. The total score is the sum for the all questions.]

Based on this satisfaction score, we present here the  *comments* and *final comments*  for the  `r NbAnswers` less and  `r NbAnswers` most satisfied participants.  


```{r DataNum}
# data.feedback <- data.feedback %>%
#   mutate(Total =  )



# Function to convert character variables to numeric
char_to_num <- function(x) {
  x_levels <- c("Strongly disagree", "Disagree", "Somewhat disagree", "Somewhat agree", "Agree", "Strongly agree")
  as.numeric(factor(x, levels = x_levels)) -1
}

# Apply function to all character variables in data frame
data.num<- lapply(data.survey[,1:5], function(x) if (is.character(x)) char_to_num(x) else x)

#names(data.num) <- paste(names(data.num), "N", sep = "_")


data.num <- as.data.frame(data.num) %>%
  mutate(Total = Relevance1 + Relevance2 + Relevance3 + Effectiveness1 + Effectiveness2 )

# Not clean but works
data.feedback <- cbind(data.feedback, data.num$Total)%>%
  rename( "Total" = "data.num$Total" )


```


```{r ResultTableN}
data.feedback %>%
  filter(str_count(Total) < 10) %>%
  arrange(Total) %>%    # Lowest Total first
  head(n= NbAnswers )%>%
  select(Total, Comments, FinalComments)%>%
  filter(xfun::is_ascii(Comments)== T) %>%   # remove Chinese characters
kable( ,
       col.names = c("Id", "Comments", "FinalComments"), 
       caption = paste(NbAnswers, "most negative learners \n"),
       booktabs = TRUE,
       longtable= TRUE) %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(1, width ="1cm") %>%
  column_spec(2 ,width = "15em")  %>%
  column_spec(3 ,width = "15em")


```
\newpage

```{r ResultTableP}

data.feedback %>%
  filter(Total > 20) %>%
  filter( Comments !="" | FinalComments != "") %>%
  arrange(desc(Total)) %>%    # Highest Total first
  head(n= NbAnswers )%>%
  select(Total, Comments, FinalComments)%>%
  #filter(xfun::is_ascii(Comments)== T) %>%   # remove Chinese characters
kable( ,
       col.names = c("Id", "Comments", "FinalComments"), 
       caption = paste(NbAnswers, "most positive learners \n"),
       booktabs = TRUE,
       longtable= TRUE) %>%
 kable_styling(full_width = FALSE)  %>%
  column_spec(1, width ="1cm") %>%
  column_spec(2 ,width = "15em")  %>%
  column_spec(3 ,width = "15em")




```


```{r}
 knitr::knit_exit()
```





\newpage

## Answers for  *`r Text.C`*
```{r CommentsTableN}

data.num %>%
  filter(str_count(Comments) >20) %>%
  arrange(Total) %>%    # Lowest Total first
  head(n= NbAnswers )%>%
  select(Total, Comments)%>%
  filter(xfun::is_ascii(Comments)== T) %>%   # remove Chinese pcp
kable( ,
       col.names = c("Id", "Comments"), 
       caption = paste("Most negative learners \n"),
       booktabs = TRUE,
       longtable= TRUE) %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(1, width ="1cm") %>%
  column_spec(2 ,width = "30em")


```


```{r CommentsTableP}

data.num %>%
  filter(Total>15 &  str_count(Comments) >20) %>%
  arrange(desc(Total)) %>%    # Highest Total first
  head(n= NbAnswers )%>%
  select(number, Comments)%>%
  filter(xfun::is_ascii(Comments)== T)%>%   # remove Chinese characters
kable( ,
       col.names = c("Id", "Comments"), 
       caption = paste("Most positive learners \n"),
       booktabs = TRUE,
       longtable= TRUE)%>%
  kable_styling(full_width = FALSE) %>%
  column_spec(1, width ="1cm") %>%
  column_spec(2 ,width = "30em")


```



```{r EXIT}
knitr::knit_exit()
```



# Lerner's paths

```{r LearnersTracks}
# Creating Learners Chronology

LearnersPaths <- course.log %>%
  filter(!is.na(ActNb)) %>%
  distinct(User.full.name, Time,.keep_all = TRUE) %>%
  group_by(User.full.name) %>%
  arrange(Time) %>%
  mutate( seq_idx  = row_number()
  ) %>%
  ungroup()

# Sequence of steps by learners 
LearnersPaths <- LearnersPaths   %>%
  group_by(User.full.name) %>%
  arrange(seq_idx) %>%
  mutate( 
    Increasing  =  !is.unsorted(ActNb), 
    Nbre_Steps = n(), 
    next_step = c(ActNb[-1], NA ),
    step_diff = (next_step - ActNb)-1, 
    
    sum_neg_diff = sum( ifelse(step_diff < 0 , step_diff + 1, 0) ),
    I_back = ifelse(step_diff < 0 , 1, 0), 
    Nbre_back = sum(I_back, na.rm =TRUE),
    Tx_back =  Nbre_back /Nbre_Steps,
    
    total_diff = sum(step_diff , na.rm =TRUE),
    abs_tot_diff = sum(abs(step_diff) , na.rm =TRUE),
    rel_diff = abs_tot_diff/Nbre_Steps, 
    max_diff = max(abs(step_diff) , na.rm =TRUE)
  ) %>%
  ungroup() 

# some stats to do here...

```


```{r LearnersPath}
# maybe change the definition of "clicks"  --> seq_idx
## Trajectories of learners....

NminStep <- 200    #Selecting learners for  graph
df <- LearnersPaths  %>%
  filter(Certified == TRUE,
         Nbre_Steps >= NminStep ) %>%
  group_by(User.full.name) %>%
  select(User.full.name, ActNb, Actname, ModuleID, Certified, Country,
         seq_idx, Nbre_Steps, Increasing, next_step, step_diff) %>% 
  ungroup() %>%
  arrange(User.full.name, seq_idx)

# Jitter plot 

p <- ggplot(df, aes(x = seq_idx,
                    y= ActNb,
                    group = User.full.name,
                    Act = Actname
                    # colour =  User.full.name
                    )) +
  geom_line(alpha = 0.2, size = 0.8,
            show.legend = FALSE,
            aes(y = ActNb, 
                x = jitter(as.numeric(seq_idx, 0.5)) ,
                group=factor(User.full.name))) +
  labs(title= paste("Trajectory of",length(unique(df$User.full.name)),"learners clicking at least", NminStep,"times"  ), 
       y = "Course activity", x = "Learners chronological sequence (clics)") +
  theme_minimal()

# p

ggplotly(p)

```


# Leftovers


```{r specific }
# Catching information on a specific user 
toto <- course.log %>% 
  filter(str_detect(User.full.name, "Fangcao")) %>%
  select( User.full.name, Date, ModuleID,  Actname)%>%
  unique()

unique(toto$Date) 
```


```{r, eval = FALSE}

NbSelect <- 10  # Best and worst students (in terms of events)

#Learners event counts (top and bottom Learners)
course.log %>%
  filter(!is.na(User.full.name), 
         User.full.name != "-") %>%
  count(User.full.name) %>%
  mte(rank = dense_rank(desc(n))) %>% 
  filter(row_number() >= max(row_number()) - NbSelect | rank <= NbSelect) %>%
  ggplot()+
  aes(x=reorder(User.full.name, n), y=n, 
      fill=factor(ifelse(rank <= NbSelect, paste("Top", NbSelect),paste("Bottom", NbSelect)))) +
  geom_bar(stat='identity') +
  labs(x="Learners' ID", y="Number of events", fill="",
       subtitle = paste(NbLearners,"Learners (Final Date ", FileDate,")"))+
  ggtitle("Learners event counts (top and bottom Learners)")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=12), 
        plot.subtitle = element_text(hjust = 0.5, size=8),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  coord_flip()

```

### Activities accessed by number of Learners


```{r}
course.log %>%
  filter(!is.na(ActNb)) %>%
  mutate( ActID.lab = paste(ActNb,"-",Event.context, "-", ModuleID)) %>%
  group_by(ActID.lab) %>%
  summarise(Learners = n_distinct(User.full.name)) %>% 
  mutate(rank = dense_rank(desc(Learners))) %>% 
  filter(rank <= 40) %>% 
  ggplot()+
  aes(x=reorder(ActID.lab, Learners), y=Learners)+
  geom_bar(stat='identity')+
  labs(x="Activities", y="Number of Learners", 
       subtitle = paste(length(unique(actname))-1,"activities (Final Date ", as.Date(as.character(FileDate),format = "%Y%m%d"),")"))+
  ggtitle("Activities accessed by number of Learners (top 30 activities)")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=12),
        panel.background = element_blank(), text = element_text(size=8), 
        axis.line = element_line(colour = "black"), 
        plot.subtitle = element_text(hjust = 0.5, size=8),
        axis.title.y = element_text(size = 8))+
  coord_flip()
  
```




```{r}
course.log %>%
  filter(!is.na(ActNb),
         Date <= FileDate) %>%
  mutate( ActID.lab = paste(ActNb,"-",Event.context)) %>%
  group_by(ActID.lab) %>%
  summarise(Learners = n_distinct(User.full.name)) %>% 
  #mutate(rank = dense_rank(desc(Learners))) %>% 
  #filter(rank <= 30) %>% 
  ggplot()+
  aes(x=reorder(ActID.lab, Learners), y=Learners)+
  geom_bar(stat='identity')+
  labs(x="Activities", y="Number of Learners", 
       subtitle = paste(nrow(subset(unique(course.log[c("ActNb", "Date")]), Date==FileDate)),"activities (Date ", FileDate,")"))+
  ggtitle("Activities accessed by number of Learners")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=12),
        panel.background = element_blank(), text = element_text(size=8), 
        axis.line = element_line(colour = "black"), 
        plot.subtitle = element_text(hjust = 0.5, size=8),
        axis.title.y = element_text(size = 8))+
  coord_flip()
```

 
 - Sort by the frequency of activities 
```{r, fig.width=12,fig.height=18}
#Both Date and Date ID work. Date: the specific date since beginning; DayID: the first date = 1, and the second = 2, ...
course.log %>%
  filter(!is.na(ActNb)) %>%
  mutate(ActID.lab = paste(ActNb,"-",Event.context, "-")) %>%
  group_by(ActID.lab, Date) %>%
  summarise(Learners = n_distinct(User.full.name)) %>% 
  ggplot()+
  aes(x=Date, y=fct_rev(fct_infreq(ActID.lab)), fill=Learners)+
  geom_tile()+
  labs(x="Date", y="Activities", 
       subtitle = paste("Final date ", as.Date(as.character(FileDate),format = "%Y%m%d")))+
  ggtitle("Heatmap of the activities")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=14),
        panel.background = element_blank(), text = element_text(size=10), 
        axis.line = element_line(colour = "black"), 
        plot.subtitle = element_text(hjust = 0.5, size=8),
        axis.title.y = element_text(size = 10))+
  coord_fixed(ratio = 0.5)

```



```{r }
# course.log <-  course.log %>%
#   group_by(User.full.name, Date, Actname) %>%
#   mutate( TimeperActivity = lubridate::as.duration(Time)) %>%
#   group_by(User.full.name, Date) %>%
#   mutate(TimeperDay = sum(TimeperActivity)) %>%
#   ungroup()
#  Still a problem in this computation since there may be hours btween two event...
```


```{r}

p <- Grades %>%
 filter(!is.na(Country)) %>%
mutate(TotalTime = TotalTime/60) %>%
 ggplot() +
 aes(x = NbAct, y = GradeFinal, colour = Country, toto = Email.address) +
 geom_jitter(aes(size=as.numeric(TotalTime)), width = 0.5, height = 0.5, alpha = 0.6) +
# geom_vline (aes(xintercept =  median(TotalTime))) +
# facet_wrap(vars(Country)) +
 scale_color_hue() +
 theme_minimal()+
 theme(legend.position = "bottom")

p
#ggplotly(p)

```




# leftovers




```{r}

Grades%>%
 filter(Country != "" | Country != "NA")%>%
 group_by(Country)%>%
  summarise(Learners = n()) %>%
 ggplot() +
 aes( x=reorder(Country, Learners), y=  Learners) +
 geom_bar(aes(fill = Country), stat='identity', alpha = 0.3)+
 scale_fill_hue() +
 ggtitle("Learners origin") +
 labs(y = "Nb of learners enrolled", 
      x = "Countries (Ordered by Nb of participants)",
      caption = paste("(as of ", FileDate,")"))+
 coord_flip() +
 theme_minimal() +
 theme(legend.position = "none")


```

```{r density1, fig.height=4}
library(ggridges)
Grades %>%
 filter(Country != "" | Country != "NA")%>%
  filter(GradeFinal > 0) %>%
  group_by(Country) %>%
  mutate(AvgGrade = mean(GradeFinal, na.rm =TRUE), 
         NbLearners = n_distinct(Email.address))  %>%
  ungroup() %>%
  filter(NbLearners >5) %>%
  ggplot() +
  aes(x = GradeFinal , y = reorder(Country, AvgGrade) , fill = Country) +
  xlim( c(0,65))+
  #geom_density_ridges(stat="binline", bins=20) +
  # geom_density_ridges( alpha = 0.3) +
  stat_density_ridges(quantile_lines = FALSE, quantiles = 2, 
                        jittered_points = TRUE,
                        position = position_points_jitter(width = 0.05, height = 0),
                        point_shape = '|', point_size = 2, point_alpha = 0.3, 
                       alpha = 0.3
                      ) +
  #geom_jitter(color= SIAP.color, size=0.6, alpha=0.9) +
  ggtitle("Distribution of grades by countries ") +
  labs(x="Final Grades", y=" Countries (Ordered by Avg Grades) ", 
      subtitle = paste("Countries with more than 5 participants", "(date ", FileDate,")")) +
    theme_ridges(grid = FALSE) +
  #theme_minimal()+
  theme(legend.position = "none")
 

```

```{r}

Grades %>%
 filter(Country != "" | Country != "NA")%>%
 group_by(Country) %>%
 summarise(Learners = n_distinct(Email.address)) %>%
 ggplot() +
 aes( x=reorder(Country, Learners), y=  Learners) +
 geom_bar(aes(fill = Country),stat='identity', alpha = 0.3)+
geom_text(aes(label= Learners, color = Country), vjust= 0.3, size=3.5,)+
 scale_fill_hue() +
 ggtitle("Learners origin") +
 labs(y = "Nb of learners enrolled", 
      x = "Countries (Ordered by Nb of participants)",
      subtitle = paste("(date ", FileDate,")"))+
 coord_flip() +
 theme_minimal() +
 theme(legend.position = "none")


```

```{r density2, fig.height=4}
library(ggridges)
Grades %>%
 filter(Country != "" | Country != "NA")%>%
  filter(GradeFinal > 0) %>%
  group_by(Country) %>%
  mutate(AvgGrade = mean(GradeFinal, na.rm =TRUE), 
         NbLearners = n_distinct(Email.address))  %>%
  ungroup() %>%
  filter(NbLearners >5) %>%
  ggplot() +
  aes(x = GradeFinal , y = reorder(Country, AvgGrade) , fill = Country) +
  xlim( c(0,100))+
  #geom_density_ridges(stat="binline", bins=20) +
  # geom_density_ridges( alpha = 0.3) +
  stat_density_ridges(quantile_lines = FALSE, quantiles = 2, 
                        jittered_points = TRUE,
                        position = position_points_jitter(width = 0.05, height = 0),
                        point_shape = '|', point_size = 2, point_alpha = 0.3, 
                       alpha = 0.3
                      ) +
  #geom_jitter(color= SIAP.color, size=0.6, alpha=0.9) +
  ggtitle("Distribution of grades by countries ") +
  labs(x="Final Grades", y=" Countries (Ordered by Avg Grades) ", 
      subtitle = paste("Countries with more than 5 participants", "(date ", FileDate,")")) +
    theme_ridges(grid = FALSE) +
  #theme_minimal()+
  theme(legend.position = "none")
 

```


```{r}

# Graphics on special activities

Special <- "Satellite"

toto <-  course.log %>%
  filter(!is.na(Event.name)) %>%
  filter(str_detect(Event.context, Special))%>%
  group_by(Event.context)%>%
  summarise(Learners = n_distinct(User.full.name), 
            Module = max(ModuleID))


ggplot(toto) +
  aes(x = Event.context, y =  Learners) +
  geom_bar(aes(fill = Event.context), stat = "identity", alpha = 0.5) +
  ggtitle(paste(Special, "activities")) +
 labs(y = "Nb of learners enrolled", 
      subtitle = paste("(date ", FileDate,")"))+
  coord_flip() +
  theme_minimal()+
 theme(legend.position = "none")
```


