---
title: "Data-Based Report on Learners' Feedback "
subtitle: ""
author: "Christophe Bontemps"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    df_print: kable
    toc: no
    keep_tex: yes
    fig_width: 6.5
    fig_height: 4
    extra_dependencies: float
  word_document:
    toc: no
  html_document:
    df_print: paged
    toc: yes
    keep_md: yes
    code_folding: show
    fig_width: 6.5
    fig_height: 4
---


```{r Knitr_Global_Options, include=FALSE, cache=FALSE, echo=FALSE}
library(knitr)

# No code is shown here
knitr::opts_chunk$set(echo = FALSE)

# Other options used here 
opts_chunk$set(warning = FALSE, message = FALSE,
               fig.pos = "!H", fig.align = "center",
               autodep = TRUE, tidy = FALSE, cache = TRUE)

# In case of "weird" problem, uncomment the line below (cache issue)
opts_chunk$set(cache.rebuild=TRUE) 

# My colors:
SIAP.color <- "#0385a8"
```

`r if(knitr:::pandoc_to() == "latex") {paste("\\large")}` 


```{r libraries}
# Analysis
library(tidyverse)
library(stringr)
library(dplyr)
library(tidyr)
library(forcats)
library(lubridate)

# Nice presentation of results
library(Cairo)
library(papeR)
library(xtable)
library(data.table)
library(kableExtra)
library(modelsummary)

# Graphics 

library(plotly)
library(wesanderson)
library(patchwork)
library(wordcloud)


#Text analysis
library(stringr)        
library(tm)
### using Tidytext
library(tidytext)  
library(textdata)

```

 

```{r AllCourseParameters}
# List of courses

AllCoursesRef <- c("Gender_Self_1",
                   "DTV20_S",
                   "MLOS_S", 
                   "HealthStats2",
                   "SEEA_CF_2022", 
                   "SBR22", 
                   "MLOS22")

AllCoursesNameLong <-c( "Using gender data for analysis, communications and policy making in the context of SDG monitoring and beyond",
                        "Principles of Data Visualization for Official Statistics and SDG Indicators",
                        "Principles of Machine Learning for Official Statistics and SDGs", 
                        "Health Statistics for Monitoring Sustainable Development Goals (SDGs) - 2022",
                        "Introduction to the System of Environmental Economic Accounting-Central Framework", 
                        "Statistical Business Registers", 
                        "Machine Learning for Official Statistics and SDGs-2022")

AllCoursesStartDate <-c("2022-05-25", "2022-01-24", "2022-06-06", "2022-07-04", "2022-08-01", "2022-09-26", "2022-11-21")
AllCoursesNbModules <-c(3,6,6,5,5,7,8)
```


```{r CourseChoice}
# Course Index <<<<<< =====  Choose the course here
#i.course <- 1  # Gender
# i.course <- 2  # Dataviz
# i.course <- 3  # MLOS
# i.course <- 4  # Health
# i.course <- 5 # SEEA Central Framework
# i.course <- 6 # SBR
i.course <- 7 # MLOS22

```


```{r CourseParameters}
# Course general parameters
CourseName <- AllCoursesRef[i.course]    # Gender Self
CourseNameLong <- AllCoursesNameLong[i.course]
CourseStartDate <-AllCoursesStartDate[i.course]
NbModules <- AllCoursesNbModules[i.course]              



```
# ***`r CourseNameLong `***:  

## Gathering the data

```{r LoadData}
# Parse the data folder to find the latest files 

#### Feedback  File
# --> use Comma separated values

list.feedback<- list.files(path="Data/",pattern = glob2rx(paste0("Feedback*",CourseName,"*")),
                       full.names = TRUE,recursive = TRUE)
name_last_feedback <- list.feedback[which.max(file.mtime(list.feedback))]
data.feedback <- read.csv(name_last_feedback, encoding = "utf-8")
#data.feedback <- read.csv(name_last_feedback, locale = locale(encoding = "Latin1"))

# Date of the last file found
FileDate <-as_date(file.mtime(name_last_feedback))

```

```{r RenameVars}
# I split the string (strsplit) at a dot (which you need to escape using \\) and take out only the second element using lapply. unlist is there to coerce the list into a vector.

names(data.feedback) <- unlist(lapply(strsplit(names(data.feedback), "\\."), "[[", 2))

# Saving questions could be a good idea (does not work)
# questions <-  unlist(lapply(strsplit(names(data.feedback), "\\.."), "[[", 2))



```


```{r NonUnicode}
# remove comments written in Chinese (maybe not necessary since we imported in utf-8)
data.feedback$Results  <- str_replace_all(data.feedback$Results, "[\u2E80-\u2FD5\u3190-\u319f\u3400-\u4DBF\u4E00-\u9FCC\uF900-\uFAAD]", "")

data.feedback$Comments  <- str_replace_all(data.feedback$Comments, "[\u2E80-\u2FD5\u3190-\u319f\u3400-\u4DBF\u4E00-\u9FCC\uF900-\uFAAD]", "")
```


We base our analysis on the data collected on **`r FileDate`** recorded on the  Feedback form on Moodle platform^[file `r name_last_feedback`]. **`r nrow(data.feedback)`** different learners provided **anonymously** their feedback and comments on the course*.^[As of `r format(FileDate, "%A %d %B")`]

# Composition of the respondants

```{r StatDesc, cache =TRUE}
G_Sex <- data.feedback %>%
    ggplot() +
    aes(x= Gender ) +
    geom_histogram(stat = "count", fill = SIAP.color) +
    ggtitle("Gender") +
    coord_flip() +
    theme_minimal()

G_Org <- data.feedback %>%
  ggplot() +
  aes(x= Organization ) +
  geom_histogram(stat = "count", fill = SIAP.color) +
  ggtitle("Organization") +
  coord_flip() +
  theme_minimal()



```


```{r GraphicOrganisation}

G_Sex + G_Org + 
  plot_annotation(title = 'Respondants:',
                  caption = paste("Based on" , nrow(data.feedback)," responses (File date", FileDate,")"),
                  theme = theme(plot.title = element_text(size = 16))) 

```



```{r}
# Transforming answers into factors
library(purrr)

data.feedback[,1:10] <- data.feedback[, 1:10] %>%
  mutate_if(is.character,as.factor)  

# Gathering the labels
mylabs <- unique(levels(data.feedback$Knowledge))

```



```{r InitialGraphic}
# library(forcats)

# data.feedback %>%
#   mutate(Knowledge = factor(Knowledge,  levels= c("Strongly disagree", "Somewhat disagree", "Disagree",
#                                                   "Agree", "Somewhat agree", "Strongly agree"))) %>%
#   ggplot() +
#   aes(x= Knowledge ) +
#   geom_histogram(stat = "count", fill = SIAP.color) +
#   
#  ggtitle("TBC") +
#  labs(y = paste("Based on" ,nrow(data.feedback) ," responses" ), 
#       x = "",
#       caption = paste("(date ", FileDate,")"))+
#   coord_flip() +
#   theme_minimal()


```

```{r GraphicFunction}
library(rlang)
Response_plot <- function(data, xvar) {
  # Defining the right order for factor variables
  data[[xvar]] = factor(data[[xvar]],levels= c("Strongly disagree", "Somewhat disagree", "Disagree",
                                              "Agree", "Somewhat agree", "Strongly agree")) 

  ggplot(data)+
  aes_string(x= xvar) +
  geom_histogram(stat = "count", fill = SIAP.color, alpha = 0.5) +
  geom_vline(xintercept= 3.5, lwd = 1.5, linetype="dashed", color = "pink")+
  ggtitle(paste("On", xvar)) +
  # labs(y = paste("Based on" , nrow(data) ," responses" ),
  #      x = "")+
  coord_flip() +
  theme_minimal() +
 theme(legend.position = "none")
}
```


```{r SurveyGraphicsCreation, cache=TRUE}
# Creating Graphics

G_K <- Response_plot(data.feedback, "Knowledge")
G_C <- Response_plot(data.feedback, "Content")
G_E <- Response_plot(data.feedback, "Efficiency")
G_Q <- Response_plot(data.feedback, "Quality")
G_D <- Response_plot(data.feedback, "Design")
G_U <- Response_plot(data.feedback, "Usefulness")
```
#  Evalauation of the different dimensions of the course

We asked the participants to value their experience on the course using a 5-level scale, on 6 different dimensions: 

- **Knowledge**: *The knowledge gained from this is e-learning course is useful for my present work.*
- **Content**: *The content and scope of the e-learning course is appropriate for my level of understanding.*
- **Efficiency**: *The e-Learning platform is effective.*
- **Quality**: *The modules and the exercise are of high quality, concise and clear.*
- **Design**: *The graphic design and presentations for each module are appropriate and effective.*
- **Usefulness**: *I plan to use the skills acquired through this e-learning course for my work in the coming six months*

```{r GraphicsKCEQ, fig.height=6}
patch <- (G_K | G_C) /(G_E | G_Q) / (G_D | G_U) 
patch + 
  plot_annotation(title = 'Evaluation of the course',
                  caption = paste("Based on" , nrow(data.feedback)," responses (File date", FileDate,")"),
                  theme = theme(plot.title = element_text(size = 16))) 

```

# Text analysis from the comments



```{r Questions}
Text.R <- "How do you plan to use what you have learnt through this course? "
Text.C <- "Any comments/ suggestions on how to improve this course or the platform?"
```

Free-text comments are probably the most valuable elements for lecturers as suggestions and relevant critics can be spotted in these comments. We have **two** different free-text questions in the feedback form for this course: 

- *`r Text.R`* and, 
- *`r Text.C`*

We provide here a first descriptive analysis of the comments received. This analysis is quite crude, but allows to spot some of the most important terms used by the particpants in their comments.  `


```{r TextAnalysis}
# from https://www.r-bloggers.com/2021/05/sentiment-analysis-in-r-3/


# Get text corpus
# remove some specific terms
data.text <- data.feedback %>%
  select(Results, Comments) %>%
   mutate_all(~gsub("use |machine |learning |course| will |data", "", .))

# Create corpus
All.Comments <- rbind(data.text$Results, data.text$Comments)
corpus.R <- iconv(All.Comments)
corpus.R <- Corpus(VectorSource(corpus.R))

# Clean text
corpus.R <- tm_map(corpus.R, tolower)
corpus.R <- tm_map(corpus.R, removePunctuation)
corpus.R <- tm_map(corpus.R, removeNumbers)

cleanset.R <- tm_map(corpus.R, removeWords, stopwords('english'))
# inspect(cleanset.R[1:5])

#Text stemming – which reduces words to their root form
#cleanset.R <- tm_map(cleanset.R, stemDocument)
cleanset.R <- tm_map(cleanset.R, stripWhitespace)
#inspect(cleanset.R[1:5])

```

##  Most popular words

```{r TopWords, fig.height=6}

Terms.R <- TermDocumentMatrix(cleanset.R)
Terms.R <- as.matrix(Terms.R)

Words.R <- rowSums(Terms.R)
Words.R <- subset(Words.R, Words.R>=25)

barplot(Words.R,
        main = "Most popular words in comments", 
        #sub = Text.R,
        las = 2,
        horiz=TRUE,
        col = SIAP.color)

```



```{r}

Words.R <- sort(rowSums(Terms.R), decreasing = TRUE)
set.seed(222)
wordcloud(words = names(Words.R),
          freq = Words.R,
          max.words = 150,
          random.order = F,
          min.freq = 5,
          colors = brewer.pal(8, 'Dark2'),
          scale = c(3, 0.6),
          rot.per = 0.2)
```
\newpage

##  Sentiment analysis

We  use *sentiment analysis* to determine  whether comments belong to some sort of  " predefined opinions". This method is basically a classification algorithm based on a reference list (*Word-Emotion Association Lexicon*, Mohammad and Turney 2013) where a large set of words are already classified as "positive", "negative", "happy", "sad", "angry", etc. We use here the  comments left by the participants on the free-text fields in the evaluation form  as the raw corpus of text.  

Each comment is decomposed into words^[Only "meaningful"  extracted from each sentence, excluding stop words like  “the", "is", "at", "on”]  associated to its semantic root  ([*Stemmization*](https://towardsdatascience.com/stemming-lemmatization-what-ba782b7c0bd8) ) in order to reduce the complexity of the process. After cleaning each "meaningful"  word can be related (or not) to one class *i.e.* to a sentiment.

Each comment can then be associated with one or several "sentiments" in a matrix form and some statistics can be derived, includinga a basic count for each category, as below:  


```{r SentimentScores, cache=TRUE}
library(syuzhet) # For generating sentiment scores
scores.R <- get_nrc_sentiment(unlist(cleanset.R))

# The tidytext version consist of matching with NRC sentiment source
# see https://ladal.edu.au/sentiment.html
# nrc <-tidytext::get_sentiments("nrc")
```


```{r}
barplot(colSums(scores.R),
        las = 2,
        col = SIAP.color,
        horiz = TRUE, 
        main = "Sentiment Scores on the whole text corpus"
)
```
# Comments from learners

```{r}

data.num <- data.feedback

data.num[1:10] <-data.num[, 1:10] %>%
   mutate_if(is.character,as.factor)


data.num <- data.num %>%
  mutate_at(
    vars(one_of('Knowledge', 'Content', 'Efficiency','Quality', 'Design', 'Usefulness'  )),
    funs(case_when(
     . == "Strongly disagree" ~ 0,
     . =="Somewhat disagree" ~ 1,
     . == "Disagree" ~ 2,
     . == "Agree" ~ 3,
     . == "Somewhat agree" ~ 4,
     . == "Strongly agree" ~ 5))
  )

# Total score
data.num <- data.num %>%
  mutate( Total = Knowledge + Content + Efficiency +
                  Quality + Design + Usefulness)

# Nb Answers shown 
NbAnswers <-20

```


Since the number of comments can be important (we have `r  nrow(data.feedback)` responses), we  computed a score of satisfaction based on the 5-level scale used for each questions on Knowledge, Content, Efficiency, Quality, Design \& Usefulness.^[ For each question, a score from 0 ("*Strongly disagree*") to 5 ("*Strongly agree*") was attributed. The total score is the sum for the 6 questions] For both open-text question, we present here the  `r NbAnswers` comments  with lowest and highest scores.  


## Answers for  *`r Text.R`*

```{r ResultTableN}

data.num %>%
  filter(str_count(Results) >20) %>%
  arrange(Total) %>%    # Lowest Total first
  head(n= NbAnswers )%>%
  select(number, Results)%>%
  filter(xfun::is_ascii(Results)== T) %>%   # remove Chinese caracters
kable( ,
       col.names = c("Id", "Comments"), 
       caption = paste(NbAnswers, "most negative learners \n"),
       booktabs = TRUE,
       longtable= TRUE) %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(1, width ="1cm") %>%
  column_spec(2 ,width = "30em")


```

```{r ResultTableP}

data.num %>%
  filter(str_count(Results) >20) %>%
  arrange(desc(Total)) %>%    # highest Total first
  head(n= NbAnswers )%>%
  select(number, Results)%>%
  filter(xfun::is_ascii(Results)== T) %>%   # remove Chinese caracters
kable( ,
       col.names = c("Id", "Comments"), 
       caption = paste("Most positive learners \n"),
       booktabs = TRUE,
       longtable= TRUE) %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(1, width ="1cm") %>%
  column_spec(2 ,width = "30em")


```

\newpage

## Answers for  *`r Text.C`*
```{r CommentsTableN}

data.num %>%
  filter(str_count(Comments) >20) %>%
  arrange(Total) %>%    # Lowest Total first
  head(n= NbAnswers )%>%
  select(Total, Comments)%>%
  filter(xfun::is_ascii(Comments)== T) %>%   # remove Chinese caracters
kable( ,
       col.names = c("Id", "Comments"), 
       caption = paste("Most negative learners \n"),
       booktabs = TRUE,
       longtable= TRUE) %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(1, width ="1cm") %>%
  column_spec(2 ,width = "30em")


```


```{r CommentsTableP}

data.num %>%
  filter(Total>15 &  str_count(Comments) >20) %>%
  arrange(desc(Total)) %>%    # Highest Total first
  head(n= NbAnswers )%>%
  select(number, Comments)%>%
  filter(xfun::is_ascii(Comments)== T)%>%   # remove Chinese caracters
kable( ,
       col.names = c("Id", "Comments"), 
       caption = paste("Most positive learners \n"),
       booktabs = TRUE,
       longtable= TRUE)%>%
  kable_styling(full_width = FALSE) %>%
  column_spec(1, width ="1cm") %>%
  column_spec(2 ,width = "30em")


```



```{r EXIT}
knitr::knit_exit()
```



# Lerner's paths

```{r LearnersTracks}
# Creating Learners Chronology

LearnersPaths <- course.log %>%
  filter(!is.na(ActNb)) %>%
  distinct(User.full.name, Time,.keep_all = TRUE) %>%
  group_by(User.full.name) %>%
  arrange(Time) %>%
  mutate( seq_idx  = row_number()
  ) %>%
  ungroup()

# Sequence of steps by learners 
LearnersPaths <- LearnersPaths   %>%
  group_by(User.full.name) %>%
  arrange(seq_idx) %>%
  mutate( 
    Increasing  =  !is.unsorted(ActNb), 
    Nbre_Steps = n(), 
    next_step = c(ActNb[-1], NA ),
    step_diff = (next_step - ActNb)-1, 
    
    sum_neg_diff = sum( ifelse(step_diff < 0 , step_diff + 1, 0) ),
    I_back = ifelse(step_diff < 0 , 1, 0), 
    Nbre_back = sum(I_back, na.rm =TRUE),
    Tx_back =  Nbre_back /Nbre_Steps,
    
    total_diff = sum(step_diff , na.rm =TRUE),
    abs_tot_diff = sum(abs(step_diff) , na.rm =TRUE),
    rel_diff = abs_tot_diff/Nbre_Steps, 
    max_diff = max(abs(step_diff) , na.rm =TRUE)
  ) %>%
  ungroup() 

# some stats to do here...

```


```{r LearnersPath}
# maybe change the definition of "clicks"  --> seq_idx
## Trajectories of learners....

NminStep <- 200    #Selecting learners for  graph
df <- LearnersPaths  %>%
  filter(Certified == TRUE,
         Nbre_Steps >= NminStep ) %>%
  group_by(User.full.name) %>%
  select(User.full.name, ActNb, Actname, ModuleID, Certified, Country,
         seq_idx, Nbre_Steps, Increasing, next_step, step_diff) %>% 
  ungroup() %>%
  arrange(User.full.name, seq_idx)

# Jitter plot 

p <- ggplot(df, aes(x = seq_idx,
                    y= ActNb,
                    group = User.full.name,
                    Act = Actname
                    # colour =  User.full.name
                    )) +
  geom_line(alpha = 0.2, size = 0.8,
            show.legend = FALSE,
            aes(y = ActNb, 
                x = jitter(as.numeric(seq_idx, 0.5)) ,
                group=factor(User.full.name))) +
  labs(title= paste("Trajectory of",length(unique(df$User.full.name)),"learners clicking at least", NminStep,"times"  ), 
       y = "Course activity", x = "Learners chronological sequence (clics)") +
  theme_minimal()

# p

ggplotly(p)

```


# Leftovers


```{r specific }
# Catching information on a specific user 
toto <- course.log %>% 
  filter(str_detect(User.full.name, "Fangcao")) %>%
  select( User.full.name, Date, ModuleID,  Actname)%>%
  unique()

unique(toto$Date) 
```


```{r, eval = FALSE}

NbSelect <- 10  # Best and worst students (in terms of events)

#Learners event counts (top and bottom Learners)
course.log %>%
  filter(!is.na(User.full.name), 
         User.full.name != "-") %>%
  count(User.full.name) %>%
  mte(rank = dense_rank(desc(n))) %>% 
  filter(row_number() >= max(row_number()) - NbSelect | rank <= NbSelect) %>%
  ggplot()+
  aes(x=reorder(User.full.name, n), y=n, 
      fill=factor(ifelse(rank <= NbSelect, paste("Top", NbSelect),paste("Bottom", NbSelect)))) +
  geom_bar(stat='identity') +
  labs(x="Learners' ID", y="Number of events", fill="",
       subtitle = paste(NbLearners,"Learners (Final Date ", FileDate,")"))+
  ggtitle("Learners event counts (top and bottom Learners)")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=12), 
        plot.subtitle = element_text(hjust = 0.5, size=8),
        panel.background = element_blank(), axis.line = element_line(colour = "black"))+
  coord_flip()

```

### Activities accessed by number of Learners


```{r}
course.log %>%
  filter(!is.na(ActNb)) %>%
  mutate( ActID.lab = paste(ActNb,"-",Event.context, "-", ModuleID)) %>%
  group_by(ActID.lab) %>%
  summarise(Learners = n_distinct(User.full.name)) %>% 
  mutate(rank = dense_rank(desc(Learners))) %>% 
  filter(rank <= 40) %>% 
  ggplot()+
  aes(x=reorder(ActID.lab, Learners), y=Learners)+
  geom_bar(stat='identity')+
  labs(x="Activities", y="Number of Learners", 
       subtitle = paste(length(unique(actname))-1,"activities (Final Date ", as.Date(as.character(FileDate),format = "%Y%m%d"),")"))+
  ggtitle("Activities accessed by number of Learners (top 30 activities)")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=12),
        panel.background = element_blank(), text = element_text(size=8), 
        axis.line = element_line(colour = "black"), 
        plot.subtitle = element_text(hjust = 0.5, size=8),
        axis.title.y = element_text(size = 8))+
  coord_flip()
  
```




```{r}
course.log %>%
  filter(!is.na(ActNb),
         Date <= FileDate) %>%
  mutate( ActID.lab = paste(ActNb,"-",Event.context)) %>%
  group_by(ActID.lab) %>%
  summarise(Learners = n_distinct(User.full.name)) %>% 
  #mutate(rank = dense_rank(desc(Learners))) %>% 
  #filter(rank <= 30) %>% 
  ggplot()+
  aes(x=reorder(ActID.lab, Learners), y=Learners)+
  geom_bar(stat='identity')+
  labs(x="Activities", y="Number of Learners", 
       subtitle = paste(nrow(subset(unique(course.log[c("ActNb", "Date")]), Date==FileDate)),"activities (Date ", FileDate,")"))+
  ggtitle("Activities accessed by number of Learners")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=12),
        panel.background = element_blank(), text = element_text(size=8), 
        axis.line = element_line(colour = "black"), 
        plot.subtitle = element_text(hjust = 0.5, size=8),
        axis.title.y = element_text(size = 8))+
  coord_flip()
```

 
 - Sort by the frequency of activities 
```{r, fig.width=12,fig.height=18}
#Both Date and Date ID work. Date: the specific date since beginning; DayID: the first date = 1, and the second = 2, ...
course.log %>%
  filter(!is.na(ActNb)) %>%
  mutate(ActID.lab = paste(ActNb,"-",Event.context, "-")) %>%
  group_by(ActID.lab, Date) %>%
  summarise(Learners = n_distinct(User.full.name)) %>% 
  ggplot()+
  aes(x=Date, y=fct_rev(fct_infreq(ActID.lab)), fill=Learners)+
  geom_tile()+
  labs(x="Date", y="Activities", 
       subtitle = paste("Final date ", as.Date(as.character(FileDate),format = "%Y%m%d")))+
  ggtitle("Heatmap of the activities")+
  theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank(), 
        plot.title = element_text(hjust = 0.5, size=14),
        panel.background = element_blank(), text = element_text(size=10), 
        axis.line = element_line(colour = "black"), 
        plot.subtitle = element_text(hjust = 0.5, size=8),
        axis.title.y = element_text(size = 10))+
  coord_fixed(ratio = 0.5)

```



```{r }
# course.log <-  course.log %>%
#   group_by(User.full.name, Date, Actname) %>%
#   mutate( TimeperActivity = lubridate::as.duration(Time)) %>%
#   group_by(User.full.name, Date) %>%
#   mutate(TimeperDay = sum(TimeperActivity)) %>%
#   ungroup()
#  Still a problem in this computation since there may be hours btween two event...
```


```{r}

p <- Grades %>%
 filter(!is.na(Country)) %>%
mutate(TotalTime = TotalTime/60) %>%
 ggplot() +
 aes(x = NbAct, y = GradeFinal, colour = Country, toto = Email.address) +
 geom_jitter(aes(size=as.numeric(TotalTime)), width = 0.5, height = 0.5, alpha = 0.6) +
# geom_vline (aes(xintercept =  median(TotalTime))) +
# facet_wrap(vars(Country)) +
 scale_color_hue() +
 theme_minimal()+
 theme(legend.position = "bottom")

p
#ggplotly(p)

```




# leftovers




```{r}

Grades%>%
 filter(Country != "" | Country != "NA")%>%
 group_by(Country)%>%
  summarise(Learners = n()) %>%
 ggplot() +
 aes( x=reorder(Country, Learners), y=  Learners) +
 geom_bar(aes(fill = Country), stat='identity', alpha = 0.3)+
 scale_fill_hue() +
 ggtitle("Learners origin") +
 labs(y = "Nb of learners enrolled", 
      x = "Countries (Ordered by Nb of participants)",
      caption = paste("(as of ", FileDate,")"))+
 coord_flip() +
 theme_minimal() +
 theme(legend.position = "none")


```

```{r density1, fig.height=4}
library(ggridges)
Grades %>%
 filter(Country != "" | Country != "NA")%>%
  filter(GradeFinal > 0) %>%
  group_by(Country) %>%
  mutate(AvgGrade = mean(GradeFinal, na.rm =TRUE), 
         NbLearners = n_distinct(Email.address))  %>%
  ungroup() %>%
  filter(NbLearners >5) %>%
  ggplot() +
  aes(x = GradeFinal , y = reorder(Country, AvgGrade) , fill = Country) +
  xlim( c(0,65))+
  #geom_density_ridges(stat="binline", bins=20) +
  # geom_density_ridges( alpha = 0.3) +
  stat_density_ridges(quantile_lines = FALSE, quantiles = 2, 
                        jittered_points = TRUE,
                        position = position_points_jitter(width = 0.05, height = 0),
                        point_shape = '|', point_size = 2, point_alpha = 0.3, 
                       alpha = 0.3
                      ) +
  #geom_jitter(color= SIAP.color, size=0.6, alpha=0.9) +
  ggtitle("Distribution of grades by countries ") +
  labs(x="Final Grades", y=" Countries (Ordered by Avg Grades) ", 
      subtitle = paste("Countries with more than 5 participants", "(date ", FileDate,")")) +
    theme_ridges(grid = FALSE) +
  #theme_minimal()+
  theme(legend.position = "none")
 

```

```{r}

Grades %>%
 filter(Country != "" | Country != "NA")%>%
 group_by(Country) %>%
 summarise(Learners = n_distinct(Email.address)) %>%
 ggplot() +
 aes( x=reorder(Country, Learners), y=  Learners) +
 geom_bar(aes(fill = Country),stat='identity', alpha = 0.3)+
geom_text(aes(label= Learners, color = Country), vjust= 0.3, size=3.5,)+
 scale_fill_hue() +
 ggtitle("Learners origin") +
 labs(y = "Nb of learners enrolled", 
      x = "Countries (Ordered by Nb of participants)",
      subtitle = paste("(date ", FileDate,")"))+
 coord_flip() +
 theme_minimal() +
 theme(legend.position = "none")


```

```{r density2, fig.height=4}
library(ggridges)
Grades %>%
 filter(Country != "" | Country != "NA")%>%
  filter(GradeFinal > 0) %>%
  group_by(Country) %>%
  mutate(AvgGrade = mean(GradeFinal, na.rm =TRUE), 
         NbLearners = n_distinct(Email.address))  %>%
  ungroup() %>%
  filter(NbLearners >5) %>%
  ggplot() +
  aes(x = GradeFinal , y = reorder(Country, AvgGrade) , fill = Country) +
  xlim( c(0,100))+
  #geom_density_ridges(stat="binline", bins=20) +
  # geom_density_ridges( alpha = 0.3) +
  stat_density_ridges(quantile_lines = FALSE, quantiles = 2, 
                        jittered_points = TRUE,
                        position = position_points_jitter(width = 0.05, height = 0),
                        point_shape = '|', point_size = 2, point_alpha = 0.3, 
                       alpha = 0.3
                      ) +
  #geom_jitter(color= SIAP.color, size=0.6, alpha=0.9) +
  ggtitle("Distribution of grades by countries ") +
  labs(x="Final Grades", y=" Countries (Ordered by Avg Grades) ", 
      subtitle = paste("Countries with more than 5 participants", "(date ", FileDate,")")) +
    theme_ridges(grid = FALSE) +
  #theme_minimal()+
  theme(legend.position = "none")
 

```


```{r}

# Graphics on special activities

Special <- "Satellite"

toto <-  course.log %>%
  filter(!is.na(Event.name)) %>%
  filter(str_detect(Event.context, Special))%>%
  group_by(Event.context)%>%
  summarise(Learners = n_distinct(User.full.name), 
            Module = max(ModuleID))


ggplot(toto) +
  aes(x = Event.context, y =  Learners) +
  geom_bar(aes(fill = Event.context), stat = "identity", alpha = 0.5) +
  ggtitle(paste(Special, "activities")) +
 labs(y = "Nb of learners enrolled", 
      subtitle = paste("(date ", FileDate,")"))+
  coord_flip() +
  theme_minimal()+
 theme(legend.position = "none")
```


