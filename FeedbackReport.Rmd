---
title: "Data-Based Report on Learners' Feedback "
subtitle: ""
author: "Christophe Bontemps"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    df_print: kable
    toc: no
    keep_tex: yes
    fig_width: 6.5
    fig_height: 4
    extra_dependencies: float
  word_document:
    toc: no
  html_document:
    df_print: paged
    toc: yes
    keep_md: yes
    code_folding: show
    fig_width: 6.5
    fig_height: 4
---


```{r Knitr_Global_Options, include=FALSE, cache=FALSE, echo=FALSE}
library(knitr)

# No code is shown here
knitr::opts_chunk$set(echo = FALSE)

# Other options used here 
opts_chunk$set(warning = FALSE, message = FALSE,
               fig.pos = "!H", fig.align = "center",
               autodep = TRUE, tidy = FALSE, cache = FALSE)

# In case of "weird" problem, uncomment the line below (cache issue)
# opts_chunk$set(cache.rebuild=TRUE) 

# My colors:
SIAP.color <- "#0385a8"
```

`r if(knitr:::pandoc_to() == "latex") {paste("\\large")}` 


```{r libraries}
# Analysis

library(tidyverse)
library(stringr)
library(dplyr)
library(tidyr)
library(forcats)
library(lubridate)

# Nice presentation of results
library(Cairo)
library(papeR)
library(xtable)
library(data.table)
library(kableExtra)
library(modelsummary)

# Graphics 

library(plotly)
library(wesanderson)
library(patchwork)
library(wordcloud)


#Text analysis
library(stringr)        
library(tm)
### using Tidytext
library(tidytext)  
library(textdata)

```

 

```{r AllCourseParameters}
# List of courses

AllCoursesRef <- c("Gender_Self_1",
                   "DTV20_S",
                   "MLOS_S", 
                   "HealthStats2",
                   "SEEA_CF_2022", 
                   "SBR22", 
                   "MLOS22", 
                   "ClimateChange2023", 
                   "user_2023", 
                   "egriss_2023", 
                    "ADV23", "2023-MLOS")

AllCoursesNameLong <-c( "Using gender data for analysis, communications and policy making in the context of SDG monitoring and beyond",
                        "Principles of Data Visualization for Official Statistics and SDG Indicators",
                        "Principles of Machine Learning for Official Statistics and SDGs", 
                        "Health Statistics for Monitoring Sustainable Development Goals (SDGs) - 2022",
                        "Introduction to the System of Environmental Economic Accounting-Central Framework", 
                        "Statistical Business Registers", 
                        "Machine Learning for Official Statistics and SDGs-2022", 
                        "Compiling climate change indicators: an accounting approach", 
                        "Increasing User Engagement Around Data and Statistics", 
                        "Introduction to International Recommendations on Refugee and IDP Statistics", 
                        "Advanced Data Visualization for Official Statistics and SDG Indicators",  
                         "Machine Learning for Official Statistics and SDGs-2023")

AllCoursesStartDate <-c("2022-05-25", "2022-01-24", "2022-06-06", "2022-07-04", "2022-08-01", "2022-09-26", "2022-11-21", "2023-01-16", "2023-07-03", "2023-11-27")
AllCoursesNbModules <-c(3,6,6,5,5,7,8,6,7,8)
```


```{r CourseChoice}
# Course Index <<<<<< =====  Choose the course here
### ACHTUNG this list is not the same than for GenericReport.Rmd


#i.course <- 1  # Gender
# i.course <- 2  # Dataviz -self
# i.course <- 3  # MLOS- Self
# i.course <- 4  # Health
# i.course <- 5 # SEEA Central Framework
# i.course <- 6 # SBR
#i.course <- 7 # MLOS22
# i.course <-8 # Climate Change 2023
# i.course <-9 # User Engagement
# i.course <-10 # Refugees <--- NO MOST USED WORDS IN THIS REPORT (Blank for whatever reason)  results = 'hide' in the TopWords
# i.course <-11 # ADV23   
i.course <- 12 # MLOS23

```


```{r CourseParameters}
# Course general parameters
CourseName <- AllCoursesRef[i.course]    
CourseNameLong <- AllCoursesNameLong[i.course]
CourseStartDate <-AllCoursesStartDate[i.course]
NbModules <- AllCoursesNbModules[i.course]              



```
# ***`r CourseNameLong `***:  

## Data sets

```{r LoadData}
# Parse the data folder to find the latest files 

#### Feedback  File
# --> use Comma separated values

list.feedback<- list.files(path="Data/",pattern = glob2rx(paste0("Feedback*",CourseName,"*")),
                       full.names = TRUE,recursive = TRUE)
name_last_feedback <- list.feedback[which.max(file.mtime(list.feedback))]
data.feedback <- read.csv(name_last_feedback, encoding = "utf-8")
#data.feedback <- read.csv(name_last_feedback, locale = locale(encoding = "Latin1"))

# Date of the last file found
FileDate <-as_date(file.mtime(name_last_feedback))

```

```{r RenameVars}
# I split the string (strsplit) at a dot (which you need to escape using \\) and take out only the second element using lapply. unlist is there to coerce the list into a vector.

# names(data.feedback)[c(2, 4, 5)] <- c("G.groups", "c.Country", "D.Date")

names(data.feedback) <- unlist(lapply(strsplit(names(data.feedback), "\\."), "[[", 2))

# Saving questions could be a good idea (does not work)
# questions <-  unlist(lapply(strsplit(names(data.feedback), "\\.."), "[[", 2))



```


```{r NonUnicode}
# remove comments written in Chinese (maybe not necessary since we imported in utf-8)
#data.feedback$Results  <- str_replace_all(data.feedback$Results, "[\u2E80-\u2FD5\u3190-\u319f\u3400-\u4DBF\u4E00-\u9FCC\uF900-\uFAAD]", "")

data.feedback$Comments  <- str_replace_all(data.feedback$Comments, "[\u2E80-\u2FD5\u3190-\u319f\u3400-\u4DBF\u4E00-\u9FCC\uF900-\uFAAD]", "")
```


Our analysis uses the data collected on **`r format(FileDate, "%A %d %B")`** from the  *Feedback Form* on SIAP's Moodle platform^[File used is  *`r name_last_feedback`*]. A total of  **`r nrow(data.feedback)`** different learners provided **anonymously** their feedback and comments on the course.^[As of `r format(FileDate, "%A %d %B")`]

## Composition of the respondants

```{r StatDesc}
G_Sex <- data.feedback %>%
    ggplot() +
    aes(x= Gender ) +
    geom_histogram(stat = "count", fill = SIAP.color) +
    ggtitle("Gender") +
    coord_flip() +
    theme_minimal()

G_Org <- data.feedback %>%
  ggplot() +
  aes(x= Organization ) +
  geom_histogram(stat = "count", fill = SIAP.color) +
  ggtitle("Organization") +
  coord_flip() +
  theme_minimal()



```


```{r GraphicOrganisation}

G_Sex + G_Org +
  plot_annotation(title = 'Respondents:',
                  caption = paste("Based on" , nrow(data.feedback)," responses (File date", FileDate,")"),
                  theme = theme(plot.title = element_text(size = 16)))

```



```{r TransformFactors}
# Transforming answers into factors
library(purrr)

# Define a function to harmonize the answers
harmonize_answers <- function(answer) {
  answer <- tolower(answer)
  if (grepl("strongly agree", answer)) {
    return("Strongly agree")
  } else if (grepl("somewhat agree", answer)) {
    return("Somewhat agree")
  } else if (grepl("strongly disagree", answer)) {
    return("Strongly disagree")
  } else if (grepl("disagree", answer)) {
    return("Disagree")
  } else if (grepl("agree", answer)) {
    return("Agree")
  } else {
    return(NA)
  }
}


# Define a function to convert a variable into a factor with 6 levels
factor_6_levels <- function(variable) {
  variable <- factor(variable, levels = c("Strongly disagree", "Disagree", "Somewhat disagree", "Somewhat agree", "Agree", "Strongly agree"))
  return(variable)
}

```


```{r GraphicFunction}
library(rlang)
Response_plot <- function(data, xvar, title) {
  # Harmonize the answers for each variable
  data[[xvar]]<- sapply(data[[xvar]], harmonize_answers)

  # Convert each variable into a factor with 6 levels
   data[[xvar]] <- factor_6_levels( data[[xvar]])
  
  # Graphic

  ggplot(data)+
  aes_string(x= xvar) +
  geom_histogram(stat = "count", fill = SIAP.color, alpha = 0.5) +
  ggtitle(paste(title)) +
  coord_flip() +
  theme_minimal( ) +
 theme(legend.position = "none", 
       plot.title = element_text(size = 10))
}
```

```{r SurveySimple}
G_K <- Response_plot(data.feedback, "Knowledge", "The knowledge gained from this is e-learning course is useful for my present work.")

G_C <- Response_plot(data.feedback, "Content", "The content and scope of the e-learning course is appropriate for my level of understanding.")

G_E <- Response_plot(data.feedback, "Efficiency", "The eLearning platform is effective.")

G_Q <- Response_plot(data.feedback, "Quality", "The modules and the exercise are of high quality, concise and clear")

G_D <- Response_plot(data.feedback, "Design", "The graphic design and presentations for each module are appropriate and effective.")

G_U <- Response_plot(data.feedback, "Usefulness", "I plan to use the skills acquired through this e-learning course for my work in the coming six months")


```

```{r SurveyNewFormat, eval=FALSE}
# Creating Graphics
## Relevance: (3 questions)

# G_R1 <- Response_plot(data.feedback, "Relevance1", "The training was relevant to my work.")
# G_R2 <- Response_plot(data.feedback, "Relevance2", "The level of e-learning course content was \n appropriate for my professional background")
# G_R3 <- Response_plot(data.feedback, "Relevance3", "The scope of the e-learning course was appropriate" )
# 
# ## Effectiveness: (4 questions)
# 
# G_E1 <- Response_plot(data.feedback, "Effectiveness1", "The training effectively enhanced my knowledge \n and skills.")
# G_E2 <- Response_plot(data.feedback, "Effectiveness2", "My confidence has improved in applying \n the training  received in my work.")
# G_E3 <- Response_plot(data.feedback, "Effectiveness3", "The training method was appropriate and effective.")
# G_E4 <- Response_plot(data.feedback, "Effectiveness4", "The course content (interactive lessons) was \n of high quality, clear and concise.  ")
# 
# ##Efficiency: (2 questions)
# 
# G_Y1 <- Response_plot(data.feedback, "Efficiency1", "I was satisfied with the technical support provided \n on the SIAP e-learning platform.")
# G_Y2 <- Response_plot(data.feedback, "Efficiency2", "I was satisfied with navigating the SIAP \n e-learning platform." )

```


#  Evaluation of the different dimensions of the course

We asked the participants to value their experience on the course using a 5-level scale, on  different dimensions (*Knowledge, Usefulness, Quality*,...) 


```{r GraphicFeed, fig.height=6}
all<- (G_K + G_C) / (G_E + G_Q ) / (G_D + G_U ) 
all + 
  plot_annotation(title = 'Feedback',
                  caption = paste("Based on" , nrow(data.feedback)," responses (File date", FileDate,")"),
                  theme = theme(plot.title = element_text(size = 16))) 

```


<!-- This part is for Alternative  feedback  form with  3  topics (eval = FALSE)


- **Relevance**: (3 questions)
- **Effectiveness**: (4 questions)
- **Efficiency**: (2 questions)

## Relevance


```{r GraphicsRelev, fig.height=6, eval = FALSE}
all.R<- G_R1 / G_R2 /G_R3 
all.R + 
  plot_annotation(title = 'Relevance of the course',
                  caption = paste("Based on" , nrow(data.feedback)," responses (File date", FileDate,")"),
                  theme = theme(plot.title = element_text(size = 16))) 

```

## Effectiveness


```{r GraphicsEff, fig.height=6, eval = FALSE}
all.E <- (G_E1 | G_E2) /(G_E3 | G_E4) 
all.E + 
  plot_annotation(title = 'Effectiveness of the course',
                  caption = paste("Based on" , nrow(data.feedback)," responses (File date", FileDate,")"),
                  theme = theme(plot.title = element_text(size = 16))) 

```


## Efficiency


```{r GraphicsEffy, fig.height=6, eval = FALSE}
all.Y <- (G_Y1 / G_Y2) 
all.Y + 
  plot_annotation(title = 'Efficiency of the course',
                  caption = paste("Based on" , nrow(data.feedback)," responses (File date", FileDate,")"),
                  theme = theme(plot.title = element_text(size = 16))) 

```

-->

<!-- # Consistency of the responses -->

```{r textdata}
# Alternative feedback form with 3topics 
# data.text <- data.feedback %>%
#   select(share, Effectiveness_open, Comments, FinalComments )

# data.survey <- data.feedback %>%
#   select(Relevance1:Relevance3, Effectiveness1:Effectiveness4, Efficiency1:Efficiency2)

data.text <- data.feedback %>%
  select(Results, Comments)

data.survey <- data.feedback %>%
  select(Knowledge:Design)

```


```{r, eval = FALSE}
# 
# # Function to convert character variables to numeric
# char_to_num <- function(x) {
#   x_levels <- c("Strongly disagree", "Disagree", "Somewhat disagree", "Somewhat agree", "Agree", "Strongly agree")
#   as.numeric(factor(x, levels = x_levels)) -1
# }
# 
# # Apply function to all character variables in data frame
# data.num<- lapply(data.survey, function(x) if (is.character(x)) char_to_num(x) else x)
# names(data.num) <- paste(names(data.num), "N", sep = "_")
# 
# data.feedback <- cbind(data.feedback, data.num)

```



```{r numericscale}
# data.num[1:10] <-data.num[, 1:10] %>%
#    mutate_if(is.character,as.factor)
# 
# 
# data.num <- data.num %>%
#   mutate_at(
#     vars(one_of('Knowledge', 'Content', 'Efficiency','Quality', 'Design', 'Usefulness'  )),
#     funs(case_when(
#      . == "Strongly disagree" ~ 0,
#      . =="Somewhat disagree" ~ 1,
#      . == "Disagree" ~ 2,
#      . == "Agree" ~ 3,
#      . == "Somewhat agree" ~ 4,
#      . == "Strongly agree" ~ 5))
#   )
# 
# # Total score
# data.num <- data.num %>%
#   mutate( Total = Knowledge + Content + Efficiency +
#                   Quality + Design + Usefulness)
```



```{r PCP, eval = FALSE}
# library(GGally)
# library(viridis)
# library(hrbrthemes)

# data.num %>%
#   select(Gender,Knowledge:Usefulness) %>%
#   mutate_if(is.numeric, as.factor) %>%
# ggparcoord(
#    columns = c(2:7), 
#    groupColumn = "Gender",
#    scale = "globalminmax",
#    order = "anyClass",
#     title = "No scaling",
#     alphaLines = 0.3
#     ) +
#  theme_minimal() +
#   theme(
#     plot.title = element_text(size=10), 
#     axis.text.x =  element_text(size=9, angle = 60, hjust = 1), 
#     #axis.text.x =  element_blank(),
#     legend.position = "bottom"
#   )
```

```{r}
# https://github.com/heike/ggpcp
# install.packages("devtools")
# remotes::install_github("heike/ggpcp")
```

<!--  We represent each evaluation by a line joining the score for each question. The line for a participant with always the same answer (e.g. "Strongly agree") should be horizontal. The  colors her reflect the gender. -->

```{r}
# library(ggpcp)
# data.num %>%
# mutate_if(is.numeric, as.factor) %>%
# arrange(Knowledge, Content, Total)%>%
# pcp_select(5:10) %>%
#   pcp_scale(method = "uniminmax") %>%
#   pcp_arrange(method="from-right") %>%
#   ggplot(aes_pcp()) + 
#     geom_pcp(aes(colour = Gender ),
#              alpha = 0.6, axiswidth = c(0,0))+
#     scale_colour_manual(values=c("darkorange", "steelblue", "grey")) +
#     guides(colour=guide_legend(override.aes = list(alpha=1)))+
#   # geom_pcp_labels() +
#   labs(title = "Consistency of responses",
#        caption = paste(" Each line is one response, ",
#                        "based on", nrow(data.feedback), "responses"), 
#        y = " Responses",
#        x = "Topics in the form")+
#   
#  theme_minimal() +
#   theme(
#     plot.title = element_text(size=10), 
#     axis.text.x =  element_text(size=9, angle = 60, hjust = 1), 
#     #axis.text.x =  element_blank(),
#     legend.position = "right"
#   ) 
  



```

# Text analysis from the open fields

```{r Questions}
Text.R <- "Please share comments and suggestions on how to improve the relevance of the training to your work. "
Text.E <- "Please share comments and suggestions on how to improve the effectiveness of the course in enhancing your skills and knowledge."
Text.C <- "Please share further comments and suggestions, if any, on logistical arrangements of the e-learning course."
Text.F <-"Please let us know of any other comments you would like to share with us about the course."


```

Free-text comments are probably the most valuable elements for lecturers as suggestions and relevant critics can be spotted in these comments. 

<!--- We have **four** different free-text questions in the feedback form for this course: 

- *`r Text.R`* 
- *`r Text.E`*
- *`r Text.C`* 
- *`r Text.F`*
 -->

We provide here a first descriptive analysis of the comments received. This analysis is quite limited, but allows to spot some of the most important terms used by the participants in their comments. 


```{r }
# from https://www.r-bloggers.com/2021/05/sentiment-analysis-in-r-3/


# Get text corpus
# remove some specific terms (does not work inside sentences)
data.text <- data.text %>%
   mutate_all(~gsub("use |machine |learning| learned|can| training|
                    |course| will |data| work | Visualization | thank ", "", .))
```


```{r TextCleaning}

# Words to remove
words_to_remove <- c("use", "can", "training","work", "help",
                     "thank", "content", "platform", 
                     "online","course", "will", "learned", "knowledge",
                     "machine", "learning", "statistics",
                     "data",   "Visualization","Visualizations")

# Function to remove words from a single variable (from OpenAI)
remove_words <- function(text, words) {
  pattern <- paste0("\\b", paste(words, collapse = "|"), "\\b")
  text <- gsub(pattern, "", text, ignore.case = TRUE)
  text
}

# Apply the function to each variable in the data frame using mutate_all
data.text <- data.text %>%
  mutate_all(~ remove_words(., words_to_remove))



```


## Word cloud on open comments fields


```{r TextRelevance}
# Create corpus
# All.Comments.R <- rbind(data.text$share, data.text$Effectiveness_open)
All.Comments.R <- rbind(data.text$Results, data.text$Comments)

corpus.R <- iconv(All.Comments.R)
corpus.R <- Corpus(VectorSource(corpus.R))

# Clean text
corpus.R <- tm_map(corpus.R, tolower)
corpus.R <- tm_map(corpus.R, removePunctuation)
corpus.R <- tm_map(corpus.R, removeNumbers)

cleanset.R <- tm_map(corpus.R, removeWords, stopwords('english'))
# inspect(cleanset.R[1:5])

#Text stemming – which reduces words to their root form
#cleanset.R <- tm_map(cleanset.R, stemDocument)
cleanset.R <- tm_map(cleanset.R, stripWhitespace)

# we reduce the dimension here 
#cleanset.R <- cleanset.R[1:100]

```

```{r TopWordsRelevance, fig.height=6, results ='hide', fig.show='hide'}
### NO FIGURE SHOWED HERE !!!

Terms.R <- TermDocumentMatrix(cleanset.R)
Terms.R <- as.matrix(Terms.R)

Words.R <- rowSums(Terms.R)
Words.R <- subset(Words.R, Words.R>=40)

barplot(Words.R,
        main = "Most popular words (Results and Comments)", 
        # sub = "Relevance and Effectiveness",
        xlim = c(0, 100), 
        ylim = c(0, 100), 
        las = 2,
        horiz=TRUE,
        col = SIAP.color)

```

```{r}

Words.R <- sort(rowSums(Terms.R), decreasing = TRUE)
set.seed(222)
wordcloud(words = names(Words.R),
          freq = Words.R,
          max.words = 150,
          random.order = F,
          min.freq = 5,
          colors = brewer.pal(8, 'Dark2'),
          scale = c(3, 0.6),
          rot.per = 0.2)
```
<!-- This part is for Alternative  feedback  form with  3  topics 
## Word cloud on *Comments* 


```{r TextComments, eval = FALSE}
# Create corpus
All.Comments.C <- rbind(data.text$Comments, data.text$FinalComments)
corpus.C <- iconv(All.Comments.C)
corpus.C <- Corpus(VectorSource(corpus.C))

# Clean text
corpus.C <- tm_map(corpus.C, tolower)
corpus.C <- tm_map(corpus.C, removePunctuation)
corpus.C <- tm_map(corpus.C, removeNumbers)

cleanset.C <- tm_map(corpus.C, removeWords, stopwords('english'))
# inspect(cleanset.C[1:5])

#Text stemming – which reduces words to their root form
#cleanset.C <- tm_map(cleanset.C, stemDocument)
cleanset.C <- tm_map(cleanset.C, stripWhitespace)
#inspect(cleanset.C[1:5])

```

```{r TopWordsComments, fig.height=6,  results ='hide', fig.show='hide', eval = FALSE}
### NO FIGURE SHOWED HERE !!!

Terms.C <- TermDocumentMatrix(cleanset.C)
Terms.C <- as.matrix(Terms.C)

Words.C <- rowSums(Terms.C)
Words.C <- subset(Words.C, Words.C>=25)

barplot(Words.C,
        main = "Most popular words (comments)", 
        #sub = Text.C,
        xlim = c(0, 1000), 
        ylim = c(0, 10), 
        las = 2,
        horiz=TRUE,
        col = SIAP.color)

```

```{r, eval = FALSE}

Words.C <- sort(rowSums(Terms.C), decreasing = TRUE)
set.seed(222)
wordcloud(words = names(Words.C),
          freq = Words.C,
          max.words = 150,
          random.order = F,
          min.freq = 5,
          colors = brewer.pal(8, 'Dark2'),
          scale = c(3, 0.6),
          rot.per = 0.2)
```



-->


\newpage

#  Sentiment analysis

We  use *sentiment analysis* to determine  whether comments belong to some sort of  " predefined opinions". This method is basically a classification algorithm based on a reference list (*Word-Emotion Association Lexicon*, Mohammad and Turney 2013) where a large set of words are already classified as "positive", "negative", "happy", "sad", "angry", etc. We use here the  comments left by the participants on the free-text fields in the evaluation form  as the raw corpus of text.  

Each comment is decomposed into words^[Only "meaningful"  extracted from each sentence, excluding stop words like  “the", "is", "at", "on”]  associated to its semantic root  ([*Stemmization*](https://towardsdatascience.com/stemming-lemmatization-what-ba782b7c0bd8) ) in order to reduce the complexity of the process. After cleaning each "meaningful"  word can be related (or not) to one class *i.e.* to a sentiment.

Each comment can then be associated with one or several "sentiments" in a matrix form and some statistics can be derived, including a basic count for each category, as below:  


```{r SentimentScores}


library(syuzhet) # For generating sentiment scores

# cleanset <- c(unlist(cleanset.R),unlist(cleanset.C))

cleanset <- c(unlist(cleanset.R))
# This takes time
scores <- get_nrc_sentiment(cleanset)



# The tidytext version consist of matching with NRC sentiment source
# see https://ladal.edu.au/sentiment.html
# nrc <-tidytext::get_sentiments("nrc")
```


```{r}
counts <-colSums(scores)
barplot(counts, horiz = TRUE, 
        col = "lightblue", 
        xlim = c(0, max(counts) * 1.1), 
        las = 2,
        border = NA,
        main = "Sentiment Scores (All text) ")

text(x = counts, 
     y = 1:length(counts), 
     labels = paste0(names(counts), ": ", counts), 
     col = "blue", pos = 3)
```


\newpage

# Comments from learners

```{r nbAnswers}
# Nb Answers shown 
NbAnswers <-20

```


Since the number of comments can be important (we have `r  nrow(data.feedback)` responses), we  computed a score of satisfaction based on the 5-level scale used for each closed-form question.^[ For each question, a score from 0 ("*Strongly disagree*") to 5 ("*Strongly agree*") was attributed. The total score is the sum for the all questions.]

Based on this satisfaction score, we present here the  *comments* and *final comments*  for the  `r NbAnswers` less and  `r NbAnswers` most satisfied participants.  


```{r DataNum}
# data.feedback <- data.feedback %>%
#   mutate(Total =  )



# Function to convert character variables to numeric
char_to_num <- function(x) {
  x_levels <- c("Strongly disagree", "Disagree", "Somewhat disagree", "Somewhat agree", "Agree", "Strongly agree")
  as.numeric(factor(x, levels = x_levels)) -1
}

# Apply function to all character variables in data frame
data.num<- lapply(data.survey[,1:5], function(x) if (is.character(x)) char_to_num(x) else x)

#names(data.num) <- paste(names(data.num), "N", sep = "_")


# data.num <- as.data.frame(data.num) %>%
#   mutate(Total = Relevance1 + Relevance2 + Relevance3 + Effectiveness1 + Effectiveness2 )

data.num <- as.data.frame(data.num) %>%
  mutate(Total = Knowledge + Content + Efficiency  + Quality + Design  )

# Not clean but works
data.feedback <- cbind(data.feedback, data.num$Total)%>%
  rename( "Total" = "data.num$Total" )


```


```{r ResultTableN}
data.feedback %>%
  filter(str_count(Total) < 10) %>%
  filter( Comments !="" & Comments !="-" ) %>%
  arrange(Total) %>%    # Lowest Total first
  head(n= NbAnswers )%>%
  select(Total, Results, Comments)%>%
  filter(xfun::is_ascii(Comments)== T) %>%   # remove Chinese characters
kable( ,
       col.names = c("Id", "What use?", "Comments"), 
       caption = paste("Comments from",NbAnswers, "**most negative** learners \n"),
       booktabs = TRUE,
       longtable= TRUE) %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(1, width ="1cm") %>%
  column_spec(2 ,width = "15em")%>%
  column_spec(3 ,width = "15em") 


```
\newpage

```{r ResultTableP}

data.feedback %>%
  filter(Total > 20) %>%
  filter( Comments !="" & Comments != "-") %>%
  arrange(desc(Total)) %>%    # Highest Total first
  head(n= NbAnswers )%>%
  select(Total, Results,Comments)%>%
  #filter(xfun::is_ascii(Comments)== T) %>%   # remove Chinese characters
kable( ,
       col.names = c("Id", "What use?", "Comments"), 
       caption = paste("Comments from", NbAnswers, "most positive learners \n"),
       booktabs = TRUE,
       longtable= TRUE) %>%
 kable_styling(full_width = FALSE)  %>%
  column_spec(1, width ="1cm") %>%
  column_spec(2 ,width = "20em") %>%
  column_spec(3 ,width = "15em") 




```



```{r reportexport, message=FALSE, warning=FALSE, echo = FALSE, results='hide',}
# This will copy the previous feedback report not the current one
library(here)
Report.name <- paste0("Feedback-", CourseName,"-", FileDate)
# 
# Export a copy with course name
file.copy(from = here("FeedbackReport.pdf"),
          to = paste0(here("Output/Reports"),"/",Report.name,".pdf"),overwrite = TRUE)



```

```{r}
 knitr::knit_exit()
```





\newpage

## Answers for  *`r Text.C`*
```{r CommentsTableN}

data.num %>%
  filter(str_count(Comments) >20) %>%
  arrange(Total) %>%    # Lowest Total first
  head(n= NbAnswers )%>%
  select(Total, Comments)%>%
  filter(xfun::is_ascii(Comments)== T) %>%   # remove Chinese pcp
kable( ,
       col.names = c("Id", "Comments"), 
       caption = paste("Most negative learners \n"),
       booktabs = TRUE,
       longtable= TRUE) %>%
  kable_styling(full_width = FALSE) %>%
  column_spec(1, width ="1cm") %>%
  column_spec(2 ,width = "30em")


```


```{r CommentsTableP}

data.num %>%
  filter(Total>15 &  str_count(Comments) >20) %>%
  arrange(desc(Total)) %>%    # Highest Total first
  head(n= NbAnswers )%>%
  select(number, Comments)%>%
  filter(xfun::is_ascii(Comments)== T)%>%   # remove Chinese characters
kable( ,
       col.names = c("Id", "Comments"), 
       caption = paste("Most positive learners \n"),
       booktabs = TRUE,
       longtable= TRUE)%>%
  kable_styling(full_width = FALSE) %>%
  column_spec(1, width ="1cm") %>%
  column_spec(2 ,width = "30em")


```



```{r EXIT}
knitr::knit_exit()
```

